{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a55655cba14c313eed90e50c1cdba913",
     "grade": false,
     "grade_id": "cell-d8b377aba23d9f3a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Mandatory Assignment 1\n",
    "\n",
    "This is the second of three mandatory assignments which must be completed during the course. Note that you only need to pass 2 out of 3 assignments to be eligible for the exam.\n",
    "\n",
    "First some practical pieces of information:\n",
    "\n",
    "* When is the assignment due?: **23:59, Friday, August 5, 2022.**\n",
    "* Should i work with my group?: **Yes**. In particular, you should **only hand in 1 assignment per group and in a comment on Absalon write your group number and all group members**. \n",
    "\n",
    "The assignment consists of problems from the exercise sets that you have solved so far, problems from the exercises that have been modified a little to better suit the structure of the assignment and finally also new problems not seen in the exercises. \n",
    "\n",
    "**Note**: \n",
    "- It is important that you submit your edited version of this [notebook](https://fileinfo.com/extension/ipynb#:~:text=An%20IPYNB%20file%20is%20a,Python%20language%20and%20their%20data.) as a .ipynb file and nothing else. Do not copy your answers into another notebook that you have made. \n",
    "- Don't delete the empty non-editable (unless you specifically change the metadata) cells below each question. Those are hidden tests used by the `nbgrader` software to grade the assignment.\n",
    "- It is recommended to clone our [github repository](https://github.com/isdsucph/isds2022) and copy the entire `assignment1` folder to somewhere on your computer and complete the assignment in this folder.\n",
    "- It is good practice to always restart your notebook and run all cells before submitting or delivering your notebook to somebody else. This is to make sure that all cells run without raising any errors breaking the flow of the notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from zipfile import ZipFile\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "459a25bfbfe70234fb99397dd7a844c4",
     "grade": false,
     "grade_id": "cell-e5576badd2b58d90",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Problems from Exercise Set 2:\n",
    "\n",
    "This time we are going to **read the weather data from a csv file** located in this assignment directory instead of requesting the website.\n",
    "The file is called `weather_data_1870-1875.csv` and consists of weather data for the period 1870-1875. The csv file contains data which has been constructed by concatenating the _non-processed_ data from 1870-1875. In a later exercise we will need metadata about the stations so the weather data comes bundled inside a zip file called `data.zip` together with the metadata files. \n",
    "\n",
    "First, we want to create a folder to extract the data inside the zip file to. We'll use the [`Path`](https://docs.python.org/3/library/pathlib.html#pathlib.Path) object from the [`pathlib`](https://docs.python.org/3/library/pathlib.html) module to create our data folder. With the `Path` object we can construct new file paths by using the `/` operator. For instance, to create a new folder called `some_dir` located inside the directory containing this notebook we can write \n",
    "\n",
    "```python\n",
    "## Code snippet showing how to use the `/` operator\n",
    "# Create Path object of new folder located inside \n",
    "# the current working directory of this notebook\n",
    "fp = Path.cwd() / \"some_dir\"  \n",
    "# Use the Path object to actually create the subfolder\n",
    "Path.mkdir(fp, exist_ok=True)  \n",
    "```\n",
    "It is good practice to construct paths relative to the project directory. With `pathlib` this becomes easy, also across operating systems. If you are interested you can read more about the `pathlib` module [here](https://realpython.com/python-pathlib/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 2.X.1 (Not seen in module 2):**\n",
    "Use the code snippet above to create a subfolder located inside this directory named `data`. Store the path as a `Path` object inside the variable `fp_data`. We will use `fp_data` in the next exercise when extracting the zipfile's content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "15def5ae0510f32dca69b04ddc50b1ec",
     "grade": false,
     "grade_id": "2x1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "fp = Path.cwd() / \"data\"  \n",
    "\n",
    "# Use the Path object to actually create the subfolder\n",
    "\n",
    "fp_data = Path.mkdir(fp, exist_ok=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bae59332888da39f84684680cc31fcde",
     "grade": true,
     "grade_id": "2x1-test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3ab3bf517ced19d3f422f2f65d15d918",
     "grade": false,
     "grade_id": "cell-4ae37c71df382dbd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "> **Ex. 2.X.2 (Not seen in module 2):** Use the [`zipfile`](https://docs.python.org/3/library/zipfile.html) module to extract the content of `data.zip` to the subfolder created above. \n",
    "\n",
    "> _Hint:_ Use the [`extractall`](https://docs.python.org/3/library/zipfile.html#zipfile.ZipFile.extractall) method of the `ZipFile` object. See [here](https://thispointer.com/python-how-to-unzip-a-file-extract-single-multiple-or-all-files-from-a-zip-archive/) for a guide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "028470c2eda880b8d38bfe16a40b71a2",
     "grade": false,
     "grade_id": "2x2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We now extract all files in ZIP to the data directory\n"
     ]
    }
   ],
   "source": [
    "print('We now extract all files in ZIP to the data directory')\n",
    "\n",
    "# Create a ZipFile Object and load sample.zip in it\n",
    "with ZipFile('data.zip', 'r') as zipObj:\n",
    "# Extract all the contents of zip file in different directory\n",
    "      zipObj.extractall('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c746efc3c12830df77e2f92b375f4d61",
     "grade": true,
     "grade_id": "2x2-test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9d5325888798d10692c986771969c91c",
     "grade": false,
     "grade_id": "cell-3949fc8a0311b795",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "> **Ex. 2.3.4:** The code below runs through some of the steps we completed in exercise 2.3.4 in Module 2. As we are not going to request the website but load the data from a csv file, your task is to **rewrite parts of the function**. In particular, you need to do the following:`\n",
    ">1. Rename the function to `process_weather` instead of `load_weather`. \n",
    ">2. The function should now  take a `DataFrame` as input (the one we extracted from the zip file)\n",
    ">3. Consider whether `df_weather.iloc[:, :4]` is necessary for the weather data loaded from  the csv file. The documentation string should also be rewritten appropriately. \n",
    ">4. The function contains a sorting step. **Change it so that it first sorts by _station_, then by _datetime_. The sorting should be ascending for _station_ and descending for _datetime_.** \n",
    ">5. After having rewritten the function, load the weather data from `'weather_data_1870-1875.csv'` into a pandas dataframe, apply the `process_weather` function to this dataframe, and store the result in the variable `df_weather_period`.\n",
    "\n",
    "```python\n",
    "def load_weather(year):\n",
    "    \"\"\"Function to structure and clean weather data.\n",
    "    \n",
    "    Structuring includes removing unused columns, renaming the \n",
    "    columns and selecting only observations of maximum temperature. \n",
    "    Cleaning includes inserting missing decimal, sorting and\n",
    "    resetting the index.\n",
    "    \n",
    "    Args:\n",
    "        year (int): given year to load data from e.g. 1870\n",
    "        \n",
    "    Returns:\n",
    "        (pd.DataFrame): processed weather data for given input year\n",
    "    \"\"\"\n",
    "    url = f\"ftp://ftp.ncdc.noaa.gov/pub/data/ghcn/daily/by_year/{year}.csv.gz\"\n",
    "\n",
    "    # loads the data\n",
    "    df_weather = pd.read_csv(url, header=None)\\\n",
    "                    .iloc[:,:4] \n",
    "\n",
    "    # structure and clean data using methods chaining\n",
    "    # note that the original columns now are strings when loading the csv file\n",
    "    # and not integers as when downloading the data\n",
    "    df_out = \\\n",
    "        df_weather\\\n",
    "            .rename(columns={'0': 'station', '1': 'datetime', '2': 'obs_type', '3': 'obs_value'})\\\n",
    "            .query(\"obs_type == 'TMAX'\")\\\n",
    "            .assign(obs_value=lambda df: df['obs_value']/10)\\\n",
    "            .sort_values(by=['station', 'datetime'])\\\n",
    "            .reset_index(drop=True)\\\n",
    "            .copy() \n",
    "\n",
    "    # area process\n",
    "    df_out['area'] = df_out['station'].str[0:2]\n",
    "\n",
    "    # datetime process\n",
    "    df_out['datetime_dt'] = pd.to_datetime(df_out['datetime'], format = '%Y%m%d')\n",
    "    df_out['month'] = df_out['datetime_dt'].dt.month\n",
    "    df_out['year'] = df_out['datetime_dt'].dt.year\n",
    "\n",
    "    return df_out\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132317\n"
     ]
    }
   ],
   "source": [
    "def process_weather(df_weather):\n",
    "\n",
    "    column_names = ['station', 'datetime', 'obs_type', 'obs_value']\n",
    "    df_weather.columns = column_names \n",
    "    df_out = df_weather\\\n",
    "            .query(\"obs_type == 'TMAX'\")\\\n",
    "            .assign(obs_value=lambda df: df['obs_value']/10)\\\n",
    "            .copy()\n",
    "\n",
    "    df_out['area'] = df_out['station'].str[0:2]\n",
    "\n",
    "    # datetime process\n",
    "    df_out['datetime_dt'] = pd.to_datetime(df_out['datetime'], format = '%Y%m%d')\n",
    "    df_out['month'] = df_out['datetime_dt'].dt.month\n",
    "    df_out['year'] = df_out['datetime_dt'].dt.year\n",
    "\n",
    "    return df_out\n",
    "\n",
    "df_weather = pd.read_csv(r'data/weather_data_1870-1875.csv', header=None).iloc[1:,:4]\n",
    "df_weather_period = process_weather(df_weather)\n",
    "df_weather_period.tail(10)\n",
    "print(len(df_weather_period))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            station  datetime obs_type  obs_value\n",
      "1       ASN00014016  18700101     PRCP         51\n",
      "2       ASN00021014  18700101     PRCP          0\n",
      "3       ASN00022801  18700101     PRCP          0\n",
      "4       ASN00023000  18700101     PRCP          0\n",
      "5       ASN00026005  18700101     PRCP          0\n",
      "...             ...       ...      ...        ...\n",
      "847004  USW00093852  18751231     PRCP          0\n",
      "847005  USW00094728  18751231     TMAX         72\n",
      "847006  USW00094728  18751231     TMIN         39\n",
      "847007  USW00094728  18751231     PRCP          0\n",
      "847008  USW00094728  18751231     SNOW          0\n",
      "\n",
      "[847008 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b0fcfb2b712a697a2c519e6f2d4102b6",
     "grade": false,
     "grade_id": "problem_234",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'sort_values'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/yg/20frjj8d45z_58jvhf0cb0dm0000gn/T/ipykernel_89325/1569714675.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_weather_period\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_weather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1870\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf_weather_period\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/yg/20frjj8d45z_58jvhf0cb0dm0000gn/T/ipykernel_89325/109463131.py\u001b[0m in \u001b[0;36mprocess_weather\u001b[0;34m(year)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mdf_out\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mdf_weather\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"obs_type == 'TMAX'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'obs_value'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'sort_values'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a7189d84de812b64c7424088e3ca325b",
     "grade": true,
     "grade_id": "problem_234_tests",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "78e78d64830c5518e7ef3173d94bf33c",
     "grade": false,
     "grade_id": "cell-7a8591d457df256a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "> **Ex. 2.X.3 (Not seen in module 2):** Try to plot the observations value of `df_weather_period` by running `df_weather_period.obs_value.plot()`. Something seems off, right? Now try to inspect the problematic subset of the dataframe by running `df_weather_period[df_weather_period.obs_value < -50]`. What can these three observations be characterized as? Drop _all_ observations from the associated station from `df_weather_period`, reset the index and drop the column with the old index. Store the dataframe back into the variable `df_weather_period`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a2de59076e97751d5e76fa532723f768",
     "grade": false,
     "grade_id": "problem_notseenexercises",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>datetime</th>\n",
       "      <th>obs_type</th>\n",
       "      <th>obs_value</th>\n",
       "      <th>area</th>\n",
       "      <th>datetime_dt</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>846746</th>\n",
       "      <td>CA008101170</td>\n",
       "      <td>18751231</td>\n",
       "      <td>TMIN</td>\n",
       "      <td>-61</td>\n",
       "      <td>CA</td>\n",
       "      <td>1875-12-31</td>\n",
       "      <td>12</td>\n",
       "      <td>1875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846943</th>\n",
       "      <td>USC00298072</td>\n",
       "      <td>18751231</td>\n",
       "      <td>TMIN</td>\n",
       "      <td>-128</td>\n",
       "      <td>US</td>\n",
       "      <td>1875-12-31</td>\n",
       "      <td>12</td>\n",
       "      <td>1875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846720</th>\n",
       "      <td>CA007021952</td>\n",
       "      <td>18751231</td>\n",
       "      <td>TMIN</td>\n",
       "      <td>-83</td>\n",
       "      <td>CA</td>\n",
       "      <td>1875-12-31</td>\n",
       "      <td>12</td>\n",
       "      <td>1875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846738</th>\n",
       "      <td>CA008100500</td>\n",
       "      <td>18751231</td>\n",
       "      <td>TMIN</td>\n",
       "      <td>-122</td>\n",
       "      <td>CA</td>\n",
       "      <td>1875-12-31</td>\n",
       "      <td>12</td>\n",
       "      <td>1875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846594</th>\n",
       "      <td>AU000005901</td>\n",
       "      <td>18751231</td>\n",
       "      <td>TMAX</td>\n",
       "      <td>-80</td>\n",
       "      <td>AU</td>\n",
       "      <td>1875-12-31</td>\n",
       "      <td>12</td>\n",
       "      <td>1875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>USC00271682</td>\n",
       "      <td>18700101</td>\n",
       "      <td>TMIN</td>\n",
       "      <td>-56</td>\n",
       "      <td>US</td>\n",
       "      <td>1870-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>EZE00100082</td>\n",
       "      <td>18700101</td>\n",
       "      <td>TMIN</td>\n",
       "      <td>-52</td>\n",
       "      <td>EZ</td>\n",
       "      <td>1870-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>USC00043157</td>\n",
       "      <td>18700101</td>\n",
       "      <td>TMIN</td>\n",
       "      <td>-133</td>\n",
       "      <td>US</td>\n",
       "      <td>1870-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>GME00125218</td>\n",
       "      <td>18700101</td>\n",
       "      <td>TMIN</td>\n",
       "      <td>-55</td>\n",
       "      <td>GM</td>\n",
       "      <td>1870-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>CA006166416</td>\n",
       "      <td>18700101</td>\n",
       "      <td>TMIN</td>\n",
       "      <td>-78</td>\n",
       "      <td>CA</td>\n",
       "      <td>1870-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1870</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31194 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            station  datetime obs_type  obs_value area datetime_dt  month  \\\n",
       "846746  CA008101170  18751231     TMIN        -61   CA  1875-12-31     12   \n",
       "846943  USC00298072  18751231     TMIN       -128   US  1875-12-31     12   \n",
       "846720  CA007021952  18751231     TMIN        -83   CA  1875-12-31     12   \n",
       "846738  CA008100500  18751231     TMIN       -122   CA  1875-12-31     12   \n",
       "846594  AU000005901  18751231     TMAX        -80   AU  1875-12-31     12   \n",
       "...             ...       ...      ...        ...  ...         ...    ...   \n",
       "169     USC00271682  18700101     TMIN        -56   US  1870-01-01      1   \n",
       "107     EZE00100082  18700101     TMIN        -52   EZ  1870-01-01      1   \n",
       "159     USC00043157  18700101     TMIN       -133   US  1870-01-01      1   \n",
       "112     GME00125218  18700101     TMIN        -55   GM  1870-01-01      1   \n",
       "86      CA006166416  18700101     TMIN        -78   CA  1870-01-01      1   \n",
       "\n",
       "        year  \n",
       "846746  1875  \n",
       "846943  1875  \n",
       "846720  1875  \n",
       "846738  1875  \n",
       "846594  1875  \n",
       "...      ...  \n",
       "169     1870  \n",
       "107     1870  \n",
       "159     1870  \n",
       "112     1870  \n",
       "86      1870  \n",
       "\n",
       "[31194 rows x 8 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_weather_period.obs_value.plot()\n",
    "plt.show()\n",
    "df_weather_period[df_weather_period.obs_value < -50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5971a3b2c04c14fb5fb5f180e25ff481",
     "grade": true,
     "grade_id": "problem_notseenexercises_tests",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b1b79752e5634da4d89aa3ae634563e0",
     "grade": false,
     "grade_id": "cell-c2f8ff075ab551a8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "> **Ex. 2.3.2:** \n",
    "Continuing with the `df_weather_period` from last exercise, do the following:\n",
    "> 1. Convert the `area` column to a categorical variable. \n",
    "> 2. Transform the `obs_value` column from a continuous to a categorical variable by partitioning it into `3` intervals. The first interval should contain observations with values of `obs_value` up to the 10% quantile. The second interval should contain observations with values of `obs_value` up to the 90% quantile. The third interval should contain the rest of the observations. Call this new column for `obs_value_cat`.  This can be done using the `pd.qcut()` method.\n",
    "> 3. Make another column with  `obs_value` as a categorical variable but this time label the 3 intervals as `[\"cold\", \"medium\", \"hot\"]`. This can be done by specifying the `labels` parameter in the `pd.qcut()` method of pandas. Call this new column for `obs_value_cat_labeled`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5a0243b6c65b39af72e8d1efead106e8",
     "grade": false,
     "grade_id": "problem_232",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'Series'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/yg/20frjj8d45z_58jvhf0cb0dm0000gn/T/ipykernel_89325/2508603656.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_weather_period\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"area\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"category\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5485\u001b[0m         ):\n\u001b[1;32m   5486\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5487\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5489\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'Series'"
     ]
    }
   ],
   "source": [
    "df_weather_period.Series(\"area\", dtype=\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "station                object\n",
       "datetime                int64\n",
       "obs_type               object\n",
       "obs_value               int64\n",
       "area                   object\n",
       "datetime_dt    datetime64[ns]\n",
       "month                   int64\n",
       "year                    int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_weather_period.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6ea686468a1612c1453d6013671443b9",
     "grade": true,
     "grade_id": "problem_232_tests",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d0e767d450ff726563ebe1bdb729215f",
     "grade": false,
     "grade_id": "cell-77eabac0ab0cbce5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Problems from Exercise Set 3:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1f6944ea47bde40b92ba269f19d16439",
     "grade": false,
     "grade_id": "cell-4975a2e1ab215936",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "> **Ex. 3.3.1:** Compute the mean and median maximum daily temperature for each month-year-station pair on the dataframe `df_weather_period` from last exercise by using the _split-apply-combine_ procedure. Store the results in new columns `tmax_mean` and `tmax_median`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ce92e895d0a63283094fe6c661cb5b66",
     "grade": false,
     "grade_id": "problem_331",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b200933c81339b97661155bc29d76cef",
     "grade": true,
     "grade_id": "problem_331_tests",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0e4d376c6fe462ddc61d2839b982968b",
     "grade": false,
     "grade_id": "cell-7e77713f98953bac",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "> **Ex. 3.3.2:** Plot the monthly max,min, mean, first and third quartiles for maximum temperature for the station with ID _'CA006110549'_ from `df_weather_period`.\n",
    "\n",
    "> *Hint*: the method `describe` computes all these measures. Try to make your plot look like the one below. \n",
    "\n",
    "<img src=\"station_data_plot.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ca1afdbf1edee8beacbfc1e95d6ac2e4",
     "grade": true,
     "grade_id": "problem_332_tests",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cf7d78380538170cdb3f8da6d976c6cd",
     "grade": false,
     "grade_id": "cell-539af69a1ea23069",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "> **Ex. 3.3.3: (MODIFIED FOR ASSIGNMENT 1)** We want to use the location data of the weather stations and merge this onto `df_weather_period`. The file with station location data is called  `ghcnd-stations.txt` and is stored in the `data.zip` file. Therefore, by Ex. 2.X.2, it should now be located in the `data` folder of this directory. `pandas` has a function named [`read_fwf`](https://pandas.pydata.org/docs/reference/api/pandas.read_fwf.html) which can be used to read a txt file with a fixed width format (each variable spans a fixed amount of columns). The function is neat and can infer how many columns each variable spans automatically (if the `infer_nrows` parameter is set properly). One can also manually set the `colspecs` parameter equal to a list of tuples containing the fixed-width intervals that the variables span. In the following exercise we will use some extra time and do the job manually to practice our txt file and string skills. Specifically, we will extract the list of tuples with fixed-widht information together with the column names and datatypes from the `ghcnd-stations-column-metadata.txt` file (also included in the `data.zip` file). \n",
    "\n",
    "> The `ghcnd-stations-column-metadata.txt` file looks like this: \n",
    "\n",
    "```\n",
    "------------------------------\n",
    "Variable   Columns   Type\n",
    "------------------------------\n",
    "ID            1-11   Character\n",
    "LATITUDE     13-20   Real\n",
    "LONGITUDE    22-30   Real\n",
    "ELEVATION    32-37   Real\n",
    "STATE        39-40   Character\n",
    "NAME         42-71   Character\n",
    "GSN FLAG     73-75   Character\n",
    "HCN/CRN FLAG 77-79   Character\n",
    "WMO ID       81-85   Character\n",
    "------------------------------\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f4d926a239ad69a32e6ddcb443ef42a0",
     "grade": false,
     "grade_id": "cell-6a3113e42875692a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "> **Ex. 3.3.3.1:** Read the `ghcnd-stations-column-metadata.txt` using the `with` keyword, see [here](https://docs.python.org/3/tutorial/inputoutput.html#reading-and-writing-files), and store it in a variable called `column_metadata`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "be143fcf053d269b2048157e33dc225c",
     "grade": false,
     "grade_id": "3331",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Variable   Columns   Type\n",
      "------------------------------\n",
      "ID            1-11   Character\n",
      "LATITUDE     13-20   Real\n",
      "LONGITUDE    22-30   Real\n",
      "ELEVATION    32-37   Real\n",
      "STATE        39-40   Character\n",
      "NAME         42-71   Character\n",
      "GSN FLAG     73-75   Character\n",
      "HCN/CRN FLAG 77-79   Character\n",
      "WMO ID       81-85   Character\n",
      "------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "with open('data/ghcnd-stations-column-metadata.txt', encoding=\"utf-8\") as g:\n",
    "    column_metadata = g.read()\n",
    "print(column_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1406fd53b4dd29083588279108f8b861",
     "grade": true,
     "grade_id": "3331-test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5d348ada2f5d006ebbb11b024f7139bc",
     "grade": false,
     "grade_id": "cell-9c66cca32bfbef31",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "> **Ex. 3.3.3.2:** Split `column_metadata` into a list of strings by applying the method `split` with the proper argument. Subset the resulting list and extract all lines from index `3` to `12` (non-inclusive) of the variable. Store the final list in a variable named `lines`. Inspect the result to make sure the relevant rows of the txt file has been extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6850caaabe8ccf9c93f8449beda38043",
     "grade": false,
     "grade_id": "3332",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ID            1-11   Character',\n",
       " 'LATITUDE     13-20   Real',\n",
       " 'LONGITUDE    22-30   Real',\n",
       " 'ELEVATION    32-37   Real',\n",
       " 'STATE        39-40   Character',\n",
       " 'NAME         42-71   Character',\n",
       " 'GSN FLAG     73-75   Character',\n",
       " 'HCN/CRN FLAG 77-79   Character',\n",
       " 'WMO ID       81-85   Character']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "lines = column_metadata.split('\\n')\n",
    "lines = lines[3:12]\n",
    "lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a01223ced1b81abc7bb54537a1923fd3",
     "grade": true,
     "grade_id": "3332-tests",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7a2d97eb10f8245bcb67a28a98be2d91",
     "grade": false,
     "grade_id": "cell-6d6084e723953822",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "> **Ex. 3.3.3.3:** Inspecting each line of the `lines` variable we see that the information about the column widths are all located from index `13` up and including index `17`. Finish the `get_colspecs` function below to extract the fixed width information from the `lines` variable by completing the steps below:\n",
    "1. Use a list comprehension to loop through each line of the file\n",
    "2. Index each line by the relevant indices written above\n",
    "3. Strip leading whitespace of each element (if necessary)\n",
    "\n",
    "> Finally, apply `get_colspecs` to the `lines` variable and store the result in a new variable called `colspecs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ca2823ed345d0dd66e8782cd4da05ea2",
     "grade": false,
     "grade_id": "3333",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1-11',\n",
       " '13-20',\n",
       " '22-30',\n",
       " '32-37',\n",
       " '39-40',\n",
       " '42-71',\n",
       " '73-75',\n",
       " '77-79',\n",
       " '81-85']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_colspecs(lines):\n",
    "    \"\"\"Extracts colspecs from `ghcnd-stations-column-metadata.txt`.\n",
    "    \n",
    "    Args:\n",
    "        lines (list[str]): \n",
    "            list of relevant rows from `ghcnd-stations-column-metadata.txt` \n",
    "    \n",
    "    Returns:\n",
    "        (list[str]): \n",
    "            list of extracted colspecs i.e. ['1-11', '13-20', ..., '81-85']\n",
    "    \"\"\"\n",
    "    colspec_idx_start = 13\n",
    "    colspec_idx_end = 17 + 1  # Including idx 17\n",
    "    colspecs = []\n",
    "    [colspecs.append(line[colspec_idx_start:colspec_idx_end].strip()) for line in lines]\n",
    "    return colspecs\n",
    "\n",
    "\n",
    "# YOUR CODE HERE\n",
    "colspecs = get_colspecs(lines)\n",
    "colspecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "44cd16c209eaf640a81923fb6c6ad3f1",
     "grade": true,
     "grade_id": "3333-tests",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b4c3b22be2785fd9a8e77273cb088905",
     "grade": false,
     "grade_id": "cell-6d9084804240b2d8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "> **Ex. 3.3.3.4:** Write a function named `get_colspec_pair` which takes as input a string variable named `colspec` and returns a tuple of integers. Specifically, the function should take a string similar to each element of `colspecs`, split this string by `-` and return a tuple of integers where\n",
    "1. The first integer should have `1` subtracted from it (Python is 0-indexed!)\n",
    "2. The second integer should stay as it is (the intervals provided to the pandas function `read_fwf` should be non-inclusive)\n",
    "> As an example, applying the function to `\"1-11\"` and `\"13-20\"` should yield the following results:\n",
    "\n",
    "```python\n",
    "print(get_colspec_pair(\"1-11\"))\n",
    "## output: (0, 11)\n",
    "\n",
    "print(get_colspec_pair(\"13-20\"))\n",
    "## output: (12, 20)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7fa3780ae35b45977761ba2fb454216a",
     "grade": false,
     "grade_id": "3334",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "def get_colspec_pair(string):\n",
    "    split = string.split('-')\n",
    "    tuple_out = (int(split[0])-1,int(split[1]))\n",
    "    return tuple_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8fee8d5b0d56d0ec1a96ed593c59a0d4",
     "grade": true,
     "grade_id": "3334-tests",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0ff7f17567aa4e2fbb44af24bdbcc986",
     "grade": false,
     "grade_id": "cell-cbaa1e1dca8e3015",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "> **Ex. 3.3.3.5:** Use the `get_colspec_pair` function in a list comprehension where you apply the function to each element in `colspecs`. Store the result in a variable named `colspec_pairs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3afbf83d84156e24b17573026dfa8248",
     "grade": false,
     "grade_id": "3335",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "colspec_pairs = [get_colspec_pair(colspec) for colspec in colspecs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a12fae1b1b368de38f3c30a3e1cdc965",
     "grade": true,
     "grade_id": "3335-tests",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2be26e96b4592760cfc20c18c6da9b1e",
     "grade": false,
     "grade_id": "cell-5535ad3d8666836b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "> **Ex. 3.3.3.6:** Because the fixed width column information spans the interval from `13` up and including index `17`, we know that the entries from `0` to `13` (non-inclusive) are the column names and the entries from `18` to the end of each line are the data types. Write two functions named `get_column_names` and `get_column_dtypes` which return a list of column names and a list of the data types of the columns, respectively. Remember to strip all redundant whitespace using the string method `strip`. Apply the function `get_column_names` to the `lines` variable and store the output in a variable named `column_names`. Likewise, apply the function `get_column_dtypes` to the `lines` variable and store the output in a variable named `column_dtypes`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f19450632f6c6d1d4d948405258b3f5c",
     "grade": false,
     "grade_id": "3336",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "def get_column_names(lines):\n",
    "    colspec_idx_start = 0\n",
    "    colspec_idx_end = 13  # Excluding idx 13\n",
    "    colspecs = []\n",
    "    [colspecs.append(line[colspec_idx_start:colspec_idx_end].rstrip()) for line in lines]\n",
    "    return colspecs\n",
    "\n",
    "column_names = get_column_names(lines)\n",
    "\n",
    "def get_column_types(lines):\n",
    "    colspec_idx_start = 18\n",
    "    colspecs = []\n",
    "    [colspecs.append(line[colspec_idx_start:].strip()) for line in lines]\n",
    "    return colspecs\n",
    "\n",
    "column_dtypes = get_column_types(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8a4ad3c2aaa3e244b71d02a9c0d99303",
     "grade": true,
     "grade_id": "3336-tests",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "42c0ef12aadd154859e3b41b8c7fabc1",
     "grade": false,
     "grade_id": "cell-6a9d81f37628d1ad",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "> **Ex. 3.3.3.7:** Replace each `\"character\"` entry with `\"str\"` and each `\"real\"` entry with `\"float32\"` of the list `column_dtypes`. Store the result of this in the same variable `column_dtypes`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2c43672a0ccde0a6cb5b628a91dfcd4d",
     "grade": false,
     "grade_id": "3337",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['str', 'float32', 'float32', 'float32', 'str', 'str', 'str', 'str', 'str']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "for i,entry in enumerate(column_dtypes):\n",
    "    if entry == 'Character':\n",
    "        column_dtypes[i] = 'str'\n",
    "    elif entry == 'Real':\n",
    "        column_dtypes[i] = 'float32'\n",
    "column_dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f3afd09a2073e36c109317f6e1f1b56e",
     "grade": true,
     "grade_id": "3337-tests",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "517454579c02edf82638e4d2f6769d05",
     "grade": false,
     "grade_id": "cell-75834af9070629b1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "> **Ex. 3.3.3.8:** Load the `ghcnd-stations.txt` data using the `read_fwf` method of pandas setting the `names` parameter equal to `column_names` and the `colspecs` parameter equal to  `colspec_pairs`. Store the result in a variable named `locations`. Next, use the `astype` method on `locations` to set the dtypes of the columns. Use the `col_to_dtype` mapping below as input argument to `astype`. Finally, rename the `id` column to `station` and left-merge `locations` onto `df_weather_period`. Store the merged dataframe in the variable `df_weather_merged`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f95d9887f5f7d1bb9294ef49c9ac05e3",
     "grade": true,
     "grade_id": "3338",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>ELEVATION</th>\n",
       "      <th>STATE</th>\n",
       "      <th>NAME</th>\n",
       "      <th>GSN FLAG</th>\n",
       "      <th>HCN/CRN FLAG</th>\n",
       "      <th>WMO ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACW00011604</td>\n",
       "      <td>17.116699</td>\n",
       "      <td>-61.783298</td>\n",
       "      <td>10.100000</td>\n",
       "      <td>nan</td>\n",
       "      <td>ST JOHNS COOLIDGE FLD</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACW00011647</td>\n",
       "      <td>17.133301</td>\n",
       "      <td>-61.783298</td>\n",
       "      <td>19.200001</td>\n",
       "      <td>nan</td>\n",
       "      <td>ST JOHNS</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AE000041196</td>\n",
       "      <td>25.333000</td>\n",
       "      <td>55.516998</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>SHARJAH INTER. AIRP</td>\n",
       "      <td>GSN</td>\n",
       "      <td>nan</td>\n",
       "      <td>41196.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AEM00041194</td>\n",
       "      <td>25.254999</td>\n",
       "      <td>55.363998</td>\n",
       "      <td>10.400000</td>\n",
       "      <td>nan</td>\n",
       "      <td>DUBAI INTL</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>41194.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AEM00041217</td>\n",
       "      <td>24.433001</td>\n",
       "      <td>54.651001</td>\n",
       "      <td>26.799999</td>\n",
       "      <td>nan</td>\n",
       "      <td>ABU DHABI INTL</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>41217.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118487</th>\n",
       "      <td>ZI000067969</td>\n",
       "      <td>-21.049999</td>\n",
       "      <td>29.367001</td>\n",
       "      <td>861.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>WEST NICHOLSON</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>67969.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118488</th>\n",
       "      <td>ZI000067975</td>\n",
       "      <td>-20.066999</td>\n",
       "      <td>30.867001</td>\n",
       "      <td>1095.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>MASVINGO</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>67975.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118489</th>\n",
       "      <td>ZI000067977</td>\n",
       "      <td>-21.017000</td>\n",
       "      <td>31.583000</td>\n",
       "      <td>430.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>BUFFALO RANGE</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>67977.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118490</th>\n",
       "      <td>ZI000067983</td>\n",
       "      <td>-20.200001</td>\n",
       "      <td>32.616001</td>\n",
       "      <td>1132.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>CHIPINGE</td>\n",
       "      <td>GSN</td>\n",
       "      <td>nan</td>\n",
       "      <td>67983.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118491</th>\n",
       "      <td>ZI000067991</td>\n",
       "      <td>-22.216999</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>457.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>BEITBRIDGE</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>67991.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>118492 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            station   LATITUDE  LONGITUDE    ELEVATION STATE  \\\n",
       "0       ACW00011604  17.116699 -61.783298    10.100000   nan   \n",
       "1       ACW00011647  17.133301 -61.783298    19.200001   nan   \n",
       "2       AE000041196  25.333000  55.516998    34.000000   nan   \n",
       "3       AEM00041194  25.254999  55.363998    10.400000   nan   \n",
       "4       AEM00041217  24.433001  54.651001    26.799999   nan   \n",
       "...             ...        ...        ...          ...   ...   \n",
       "118487  ZI000067969 -21.049999  29.367001   861.000000   nan   \n",
       "118488  ZI000067975 -20.066999  30.867001  1095.000000   nan   \n",
       "118489  ZI000067977 -21.017000  31.583000   430.000000   nan   \n",
       "118490  ZI000067983 -20.200001  32.616001  1132.000000   nan   \n",
       "118491  ZI000067991 -22.216999  30.000000   457.000000   nan   \n",
       "\n",
       "                         NAME GSN FLAG HCN/CRN FLAG   WMO ID  \n",
       "0       ST JOHNS COOLIDGE FLD      nan          nan      nan  \n",
       "1                    ST JOHNS      nan          nan      nan  \n",
       "2         SHARJAH INTER. AIRP      GSN          nan  41196.0  \n",
       "3                  DUBAI INTL      nan          nan  41194.0  \n",
       "4              ABU DHABI INTL      nan          nan  41217.0  \n",
       "...                       ...      ...          ...      ...  \n",
       "118487         WEST NICHOLSON      nan          nan  67969.0  \n",
       "118488               MASVINGO      nan          nan  67975.0  \n",
       "118489          BUFFALO RANGE      nan          nan  67977.0  \n",
       "118490               CHIPINGE      GSN          nan  67983.0  \n",
       "118491             BEITBRIDGE      nan          nan  67991.0  \n",
       "\n",
       "[118492 rows x 9 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_to_dtype = dict(zip(column_names, column_dtypes))\n",
    "\n",
    "# YOUR CODE HERE\n",
    "locations = pd.read_fwf('data/ghcnd-stations.txt', names = column_names, colspecs = colspec_pairs)\n",
    "locations = locations.astype(col_to_dtype)\n",
    "locations = locations.rename(columns = {\"ID\": \"station\"})\n",
    "locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b9a4a76770858c976a5b06ed3ae844c1",
     "grade": false,
     "grade_id": "cell-5ba4eb25c926ef77",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "> **Ex. 3.3.3.9:** Subset `df_weather_period` by all weather stations in Ontario (all stations in Ontario have `state == \"ON\"`) and store the resulting DataFrame in `df_ontario`. Compute the average `obs_value` for each `station`. Store the result in a dictionary named `avg_obs_value_ontario` with the keys being the station names and the values the average `obs_value`. Finally, subset the `locations` dataframe by the querying all stations contained in the keys of `avg_obs_value_ontario`. Store the result in `locations_ontario`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "281bdf9651d8963912d805659386a298",
     "grade": false,
     "grade_id": "3339",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b0c4d941c8aa454f62466c826d87602a",
     "grade": true,
     "grade_id": "3339-test",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4c3a1d9147bc363623dcefcb7c27d5d5",
     "grade": false,
     "grade_id": "cell-8d4c53302d51c9db",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "> **Ex. 3.3.3.10 (OPTIONAL)**: The following exercise does not count towards the grade of this assignment. Let's try to plot the stations for Ontario on a map of Ontario. We'll use the [`folium`](http://python-visualization.github.io/folium/) package to do this. This package is not pre-installed with `anaconda`. Run the cell below to install the package or open up your terminal, activate your preferred conda environment and type `!pip install folium`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install folium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8765bee40dfff161e74121cdcf5fcb42",
     "grade": false,
     "grade_id": "cell-444d95c01e37753f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "> **Ex. 3.3.3.10 (continued)**:\n",
    "> We want to plot the stations in `locations_ontario` on top of a map of Ontario. To do this, we need to create a `folium.Marker` for each station and place this on the folium map named `m` in the cell below starting with `import folium`. To accomplish this do the following:\n",
    "- Iterate through the `zipper` defined in the cell below using a list comprehension and apply the `get_marker` function at each iteration. \n",
    "    - The `zipper` object yields a tuple of 4 values in each iteration. \n",
    "- The `avg_temp` argument of `get_marker` should take the value of each given station from the `avg_obs_value_ontario` dictionary created in the previous exercise. If the loop variable corresponding to `locations_ontario.station` is named `station_id` the value can be computed by subsetting the dictionary as  `avg_obs_value_ontario[station_id]`.\n",
    "- Store the result in a variable named `markers_ontario`. The result should be a list of `folium.Markers` for each of the stations.\n",
    "\n",
    "The resulting plot should be an interactive plot similar to the one in the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b4cd34d87209cc1d736bf17963ca1278",
     "grade": false,
     "grade_id": "cell-09786db74bccea07",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Resulting folium plot\n",
    "from IPython.display import Image\n",
    "Image(filename='ontario-example-plot.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4402f4bff9fb1f9e77ba879131dfdef4",
     "grade": true,
     "grade_id": "33310",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import folium\n",
    "\n",
    "\n",
    "def get_marker(lat, lon, station_name, avg_obs_value, icon='cloud', color=\"blue\"):\n",
    "    \"\"\"Creates a `folumn.Marker` for a given station\n",
    "    \n",
    "    Args:\n",
    "        (lat): lattitude of station\n",
    "        (lon): longitude of station\n",
    "        (station_name): name of station\n",
    "        (avg_obs_value): avg. obs_value for given station\n",
    "        \n",
    "    Returns:\n",
    "        (folium.Marker): object to be added to a folium map\n",
    "    \"\"\"\n",
    "    popup = \"\\n\".join([station_name, f\"Avg. obs_value: {avg_obs_value:.2f}\"])\n",
    "    marker = folium.Marker(\n",
    "        location=[lat, lon],\n",
    "        popup=popup,\n",
    "        icon=folium.Icon(icon=icon, color=color, )\n",
    "    )\n",
    "    return marker\n",
    "\n",
    "\n",
    "# Create folium map centered on Ontario\n",
    "# COORDS_ONTARIO = (51.730703, -86.938937)\n",
    "COORDS_ONTARIO = (43.40168574192175, -80.33021323830818)\n",
    "m = folium.Map(location=COORDS_ONTARIO, zoom_start=6)\n",
    "\n",
    "# Zipper object to iterate through\n",
    "zipper = zip(\n",
    "    locations_ontario.latitude,\n",
    "    locations_ontario.longitude,\n",
    "    locations_ontario.name,\n",
    "    locations_ontario.station   \n",
    ")\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "# add weather station markers to map \n",
    "for station_marker in markers_ontario:  \n",
    "    station_marker.add_to(m)\n",
    "m  # Display map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "eaf086f4f6724e090ef66a74eff4517e",
     "grade": false,
     "grade_id": "cell-422d30deb292b4c7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Problems from Exercise Set 4:\n",
    "\n",
    "> **Ex. 4.3.5 (sligthly modified):** This exercise consists of a set of small subelements: \n",
    ">\n",
    "> 0. Show the first five rows of the titanic dataset. What information is in the dataset?\n",
    "> 1. Use a barplot to show the probability of survival for men and women within each passenger class. \n",
    "> 2. Can you make a boxplot showing the same information (why/why not?). \n",
    "> 3. Show a boxplot for the fare-prices within each passenger class. \n",
    "> 4. Create a new subfolder as done in Ex. 2.X.1 this time named `figs`. Use the same approach as in Ex. 2.X.1 and store the `Path` object in a variable named `fp_figs`. \n",
    "> 5. Combine the two of the figures you created above into a two-panel figure and save it on your computer in the `figs` subfolder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e46d24e4bd08f8870982dd932ddd15f1",
     "grade": true,
     "grade_id": "problem_435",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 4.3.6:** Using the iris flower dataset, draw a scatterplot of sepal length and petal length. Include a second order polynomial fitted to the data. Add a title to the plot and rename the axis labels.\n",
    ">\n",
    "> _Write 3 sentences:_ Is this a meaningful way to display the data? What could we do differently?\n",
    ">\n",
    "> For a better understanding of the dataset this image might be useful:\n",
    "\n",
    "> <img src=\"example-iris-q436.png\" alt=\"Drawing\" style=\"width: 200px;\"/>\n",
    ">\n",
    "> _Hint:_ Use the `.regplot` method from seaborn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7e41badd527517260b61cead987a91cf",
     "grade": true,
     "grade_id": "problem_436",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4330f62f04b07d60e818eb1893bbf82d",
     "grade": false,
     "grade_id": "cell-e6d0c56f1cf535c5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "> **Ex. 4.3.7:** Use [pairplot with hue](https://seaborn.pydata.org/generated/seaborn.pairplot.html) to create a figure that clearly shows how the different species vary across measurements in the iris dataset. Change the color palette and remove the shading from the density plots. _Bonus:_ Try to explain how the `diag_kws` argument works (_hint:_ [read here](https://stackoverflow.com/questions/1769403/understanding-kwargs-in-python))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "19e3feab810ee078ec29408d99334983",
     "grade": true,
     "grade_id": "problem_437",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
