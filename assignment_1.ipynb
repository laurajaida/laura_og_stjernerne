{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a55655cba14c313eed90e50c1cdba913",
     "grade": false,
     "grade_id": "cell-d8b377aba23d9f3a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Mandatory Assignment 1\n",
    "\n",
    "This is the second of three mandatory assignments which must be completed during the course. Note that you only need to pass 2 out of 3 assignments to be eligible for the exam.\n",
    "\n",
    "First some practical pieces of information:\n",
    "\n",
    "* When is the assignment due?: **23:59, Friday, August 5, 2022.**\n",
    "* Should i work with my group?: **Yes**. In particular, you should **only hand in 1 assignment per group and in a comment on Absalon write your group number and all group members**. \n",
    "\n",
    "The assignment consists of problems from the exercise sets that you have solved so far, problems from the exercises that have been modified a little to better suit the structure of the assignment and finally also new problems not seen in the exercises. \n",
    "\n",
    "**Note**: \n",
    "- It is important that you submit your edited version of this [notebook](https://fileinfo.com/extension/ipynb#:~:text=An%20IPYNB%20file%20is%20a,Python%20language%20and%20their%20data.) as a .ipynb file and nothing else. Do not copy your answers into another notebook that you have made. \n",
    "- Don't delete the empty non-editable (unless you specifically change the metadata) cells below each question. Those are hidden tests used by the `nbgrader` software to grade the assignment.\n",
    "- It is recommended to clone our [github repository](https://github.com/isdsucph/isds2022) and copy the entire `assignment1` folder to somewhere on your computer and complete the assignment in this folder.\n",
    "- It is good practice to always restart your notebook and run all cells before submitting or delivering your notebook to somebody else. This is to make sure that all cells run without raising any errors breaking the flow of the notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from zipfile import ZipFile\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "459a25bfbfe70234fb99397dd7a844c4",
     "grade": false,
     "grade_id": "cell-e5576badd2b58d90",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Problems from Exercise Set 2:\n",
    "\n",
    "This time we are going to **read the weather data from a csv file** located in this assignment directory instead of requesting the website.\n",
    "The file is called `weather_data_1870-1875.csv` and consists of weather data for the period 1870-1875. The csv file contains data which has been constructed by concatenating the _non-processed_ data from 1870-1875. In a later exercise we will need metadata about the stations so the weather data comes bundled inside a zip file called `data.zip` together with the metadata files. \n",
    "\n",
    "First, we want to create a folder to extract the data inside the zip file to. We'll use the [`Path`](https://docs.python.org/3/library/pathlib.html#pathlib.Path) object from the [`pathlib`](https://docs.python.org/3/library/pathlib.html) module to create our data folder. With the `Path` object we can construct new file paths by using the `/` operator. For instance, to create a new folder called `some_dir` located inside the directory containing this notebook we can write \n",
    "\n",
    "```python\n",
    "## Code snippet showing how to use the `/` operator\n",
    "# Create Path object of new folder located inside \n",
    "# the current working directory of this notebook\n",
    "fp = Path.cwd() / \"some_dir\"  \n",
    "# Use the Path object to actually create the subfolder\n",
    "Path.mkdir(fp, exist_ok=True)  \n",
    "```\n",
    "It is good practice to construct paths relative to the project directory. With `pathlib` this becomes easy, also across operating systems. If you are interested you can read more about the `pathlib` module [here](https://realpython.com/python-pathlib/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 2.X.1 (Not seen in module 2):**\n",
    "Use the code snippet above to create a subfolder located inside this directory named `data`. Store the path as a `Path` object inside the variable `fp_data`. We will use `fp_data` in the next exercise when extracting the zipfile's content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "15def5ae0510f32dca69b04ddc50b1ec",
     "grade": false,
     "grade_id": "2x1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "fp = Path.cwd() / \"data\"  \n",
    "\n",
    "# Use the Path object to actually create the subfolder\n",
    "\n",
    "fp_data = Path.mkdir(fp, exist_ok=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bae59332888da39f84684680cc31fcde",
     "grade": true,
     "grade_id": "2x1-test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3ab3bf517ced19d3f422f2f65d15d918",
     "grade": false,
     "grade_id": "cell-4ae37c71df382dbd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "> **Ex. 2.X.2 (Not seen in module 2):** Use the [`zipfile`](https://docs.python.org/3/library/zipfile.html) module to extract the content of `data.zip` to the subfolder created above. \n",
    "\n",
    "> _Hint:_ Use the [`extractall`](https://docs.python.org/3/library/zipfile.html#zipfile.ZipFile.extractall) method of the `ZipFile` object. See [here](https://thispointer.com/python-how-to-unzip-a-file-extract-single-multiple-or-all-files-from-a-zip-archive/) for a guide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "028470c2eda880b8d38bfe16a40b71a2",
     "grade": false,
     "grade_id": "2x2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We now extract all files in ZIP to the data directory\n"
     ]
    }
   ],
   "source": [
    "print('We now extract all files in ZIP to the data directory')\n",
    "\n",
    "# Create a ZipFile Object and load sample.zip in it\n",
    "with ZipFile('data.zip', 'r') as zipObj:\n",
    "# Extract all the contents of zip file in different directory\n",
    "      zipObj.extractall('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c746efc3c12830df77e2f92b375f4d61",
     "grade": true,
     "grade_id": "2x2-test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9d5325888798d10692c986771969c91c",
     "grade": false,
     "grade_id": "cell-3949fc8a0311b795",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "> **Ex. 2.3.4:** The code below runs through some of the steps we completed in exercise 2.3.4 in Module 2. As we are not going to request the website but load the data from a csv file, your task is to **rewrite parts of the function**. In particular, you need to do the following:`\n",
    ">1. Rename the function to `process_weather` instead of `load_weather`. \n",
    ">2. The function should now  take a `DataFrame` as input (the one we extracted from the zip file)\n",
    ">3. Consider whether `df_weather.iloc[:, :4]` is necessary for the weather data loaded from  the csv file. The documentation string should also be rewritten appropriately. \n",
    ">4. The function contains a sorting step. **Change it so that it first sorts by _station_, then by _datetime_. The sorting should be ascending for _station_ and descending for _datetime_.** \n",
    ">5. After having rewritten the function, load the weather data from `'weather_data_1870-1875.csv'` into a pandas dataframe, apply the `process_weather` function to this dataframe, and store the result in the variable `df_weather_period`.\n",
    "\n",
    "```python\n",
    "def load_weather(year):\n",
    "    \"\"\"Function to structure and clean weather data.\n",
    "    \n",
    "    Structuring includes removing unused columns, renaming the \n",
    "    columns and selecting only observations of maximum temperature. \n",
    "    Cleaning includes inserting missing decimal, sorting and\n",
    "    resetting the index.\n",
    "    \n",
    "    Args:\n",
    "        year (int): given year to load data from e.g. 1870\n",
    "        \n",
    "    Returns:\n",
    "        (pd.DataFrame): processed weather data for given input year\n",
    "    \"\"\"\n",
    "    url = f\"ftp://ftp.ncdc.noaa.gov/pub/data/ghcn/daily/by_year/{year}.csv.gz\"\n",
    "\n",
    "    # loads the data\n",
    "    df_weather = pd.read_csv(url, header=None)\\\n",
    "                    .iloc[:,:4] \n",
    "\n",
    "    # structure and clean data using methods chaining\n",
    "    # note that the original columns now are strings when loading the csv file\n",
    "    # and not integers as when downloading the data\n",
    "    df_out = \\\n",
    "        df_weather\\\n",
    "            .rename(columns={'0': 'station', '1': 'datetime', '2': 'obs_type', '3': 'obs_value'})\\\n",
    "            .query(\"obs_type == 'TMAX'\")\\\n",
    "            .assign(obs_value=lambda df: df['obs_value']/10)\\\n",
    "            .sort_values(by=['station', 'datetime'])\\\n",
    "            .reset_index(drop=True)\\\n",
    "            .copy() \n",
    "\n",
    "    # area process\n",
    "    df_out['area'] = df_out['station'].str[0:2]\n",
    "\n",
    "    # datetime process\n",
    "    df_out['datetime_dt'] = pd.to_datetime(df_out['datetime'], format = '%Y%m%d')\n",
    "    df_out['month'] = df_out['datetime_dt'].dt.month\n",
    "    df_out['year'] = df_out['datetime_dt'].dt.year\n",
    "\n",
    "    return df_out\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>datetime</th>\n",
       "      <th>obs_type</th>\n",
       "      <th>obs_value</th>\n",
       "      <th>area</th>\n",
       "      <th>datetime_dt</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>847008</th>\n",
       "      <td>USW00094728</td>\n",
       "      <td>18751231</td>\n",
       "      <td>SNOW</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>1875-12-31</td>\n",
       "      <td>12</td>\n",
       "      <td>1875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846520</th>\n",
       "      <td>ASN00063004</td>\n",
       "      <td>18751231</td>\n",
       "      <td>TMAX</td>\n",
       "      <td>347</td>\n",
       "      <td>AS</td>\n",
       "      <td>1875-12-31</td>\n",
       "      <td>12</td>\n",
       "      <td>1875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>847001</th>\n",
       "      <td>USW00093820</td>\n",
       "      <td>18751231</td>\n",
       "      <td>PRCP</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>1875-12-31</td>\n",
       "      <td>12</td>\n",
       "      <td>1875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846550</th>\n",
       "      <td>ASN00072151</td>\n",
       "      <td>18751231</td>\n",
       "      <td>PRCP</td>\n",
       "      <td>0</td>\n",
       "      <td>AS</td>\n",
       "      <td>1875-12-31</td>\n",
       "      <td>12</td>\n",
       "      <td>1875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846549</th>\n",
       "      <td>ASN00072151</td>\n",
       "      <td>18751231</td>\n",
       "      <td>TMIN</td>\n",
       "      <td>150</td>\n",
       "      <td>AS</td>\n",
       "      <td>1875-12-31</td>\n",
       "      <td>12</td>\n",
       "      <td>1875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>CA008205698</td>\n",
       "      <td>18700101</td>\n",
       "      <td>TMAX</td>\n",
       "      <td>17</td>\n",
       "      <td>CA</td>\n",
       "      <td>1870-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>NLE00101991</td>\n",
       "      <td>18700101</td>\n",
       "      <td>PRCP</td>\n",
       "      <td>0</td>\n",
       "      <td>NL</td>\n",
       "      <td>1870-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>ITE00100552</td>\n",
       "      <td>18700101</td>\n",
       "      <td>PRCP</td>\n",
       "      <td>47</td>\n",
       "      <td>IT</td>\n",
       "      <td>1870-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>CA008205698</td>\n",
       "      <td>18700101</td>\n",
       "      <td>PRCP</td>\n",
       "      <td>0</td>\n",
       "      <td>CA</td>\n",
       "      <td>1870-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASN00014016</td>\n",
       "      <td>18700101</td>\n",
       "      <td>PRCP</td>\n",
       "      <td>51</td>\n",
       "      <td>AS</td>\n",
       "      <td>1870-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1870</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>847008 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            station  datetime obs_type  obs_value area datetime_dt  month  \\\n",
       "847008  USW00094728  18751231     SNOW          0   US  1875-12-31     12   \n",
       "846520  ASN00063004  18751231     TMAX        347   AS  1875-12-31     12   \n",
       "847001  USW00093820  18751231     PRCP          0   US  1875-12-31     12   \n",
       "846550  ASN00072151  18751231     PRCP          0   AS  1875-12-31     12   \n",
       "846549  ASN00072151  18751231     TMIN        150   AS  1875-12-31     12   \n",
       "...             ...       ...      ...        ...  ...         ...    ...   \n",
       "91      CA008205698  18700101     TMAX         17   CA  1870-01-01      1   \n",
       "129     NLE00101991  18700101     PRCP          0   NL  1870-01-01      1   \n",
       "120     ITE00100552  18700101     PRCP         47   IT  1870-01-01      1   \n",
       "93      CA008205698  18700101     PRCP          0   CA  1870-01-01      1   \n",
       "1       ASN00014016  18700101     PRCP         51   AS  1870-01-01      1   \n",
       "\n",
       "        year  \n",
       "847008  1875  \n",
       "846520  1875  \n",
       "847001  1875  \n",
       "846550  1875  \n",
       "846549  1875  \n",
       "...      ...  \n",
       "91      1870  \n",
       "129     1870  \n",
       "120     1870  \n",
       "93      1870  \n",
       "1       1870  \n",
       "\n",
       "[847008 rows x 8 columns]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_weather = pd.read_csv(r'data\\weather_data_1870-1875.csv', header=None)\\\n",
    "                    .iloc[1:,:4] \n",
    " \n",
    "\n",
    "column_names = ['station', 'datetime', 'obs_type', 'obs_value']\n",
    "df_weather.columns = column_names \n",
    "    \n",
    "df_out = df_weather.query(\"obs_type == 'TMAX'\")\n",
    "df_out = df_weather.assign(obs_value=lambda df: df['obs_value']/10)\n",
    "df_out = df_weather.sort_values(by=['station'], inplace=True)\n",
    "df_out = df_weather.sort_values(by=['datetime'], inplace=True, ascending=False)\n",
    "df_out = df_weather.reset_index(drop=True)\n",
    "df_out = df_weather.copy()\n",
    "\n",
    "df_out['area'] = df_out['station'].str[0:2]\n",
    "\n",
    "    # datetime process\n",
    "df_out['datetime_dt'] = pd.to_datetime(df_out['datetime'], format = '%Y%m%d')\n",
    "df_out['month'] = df_out['datetime_dt'].dt.month\n",
    "df_out['year'] = df_out['datetime_dt'].dt.year\n",
    "\n",
    "df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_weather(year):\n",
    "    \n",
    "    df_weather = pd.read_csv(r'data\\weather_data_1870-1875.csv', header=None)\\\n",
    "                    .iloc[1:,:4] \n",
    " \n",
    "\n",
    "    column_names = ['station', 'datetime', 'obs_type', 'obs_value']\n",
    "    df_weather.columns = column_names \n",
    "    \n",
    "    df_out = df_weather.query(\"obs_type == 'TMAX'\")\n",
    "    df_out = df_weather.assign(obs_value=lambda df: df['obs_value']/10)\n",
    "    df_out = df_weather.sort_values(by=['station'], inplace=True)\n",
    "    df_out = df_weather.sort_values(by=['datetime'], inplace=True, ascending=False)\n",
    "    df_out = df_weather.reset_index(drop=True)\n",
    "    df_out = df_weather.copy()\n",
    "\n",
    "    df_out['area'] = df_out['station'].str[0:2]\n",
    "\n",
    "    # datetime process\n",
    "    df_out['datetime_dt'] = pd.to_datetime(df_out['datetime'], format = '%Y%m%d')\n",
    "    df_out['month'] = df_out['datetime_dt'].dt.month\n",
    "    df_out['year'] = df_out['datetime_dt'].dt.year\n",
    "    \n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b0fcfb2b712a697a2c519e6f2d4102b6",
     "grade": false,
     "grade_id": "problem_234",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>datetime</th>\n",
       "      <th>obs_type</th>\n",
       "      <th>obs_value</th>\n",
       "      <th>area</th>\n",
       "      <th>datetime_dt</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ASN00075080</td>\n",
       "      <td>18700101</td>\n",
       "      <td>PRCP</td>\n",
       "      <td>0</td>\n",
       "      <td>AS</td>\n",
       "      <td>1870-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>SWE00138488</td>\n",
       "      <td>18700101</td>\n",
       "      <td>PRCP</td>\n",
       "      <td>2</td>\n",
       "      <td>SW</td>\n",
       "      <td>1870-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>SWE00100026</td>\n",
       "      <td>18700101</td>\n",
       "      <td>PRCP</td>\n",
       "      <td>0</td>\n",
       "      <td>SW</td>\n",
       "      <td>1870-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>CA006148100</td>\n",
       "      <td>18700101</td>\n",
       "      <td>TMIN</td>\n",
       "      <td>-44</td>\n",
       "      <td>CA</td>\n",
       "      <td>1870-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>CA006148100</td>\n",
       "      <td>18700101</td>\n",
       "      <td>TMAX</td>\n",
       "      <td>6</td>\n",
       "      <td>CA</td>\n",
       "      <td>1870-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>CA008205698</td>\n",
       "      <td>18700101</td>\n",
       "      <td>TMAX</td>\n",
       "      <td>17</td>\n",
       "      <td>CA</td>\n",
       "      <td>1870-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>NLE00101991</td>\n",
       "      <td>18700101</td>\n",
       "      <td>PRCP</td>\n",
       "      <td>0</td>\n",
       "      <td>NL</td>\n",
       "      <td>1870-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>ITE00100552</td>\n",
       "      <td>18700101</td>\n",
       "      <td>PRCP</td>\n",
       "      <td>47</td>\n",
       "      <td>IT</td>\n",
       "      <td>1870-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>CA008205698</td>\n",
       "      <td>18700101</td>\n",
       "      <td>PRCP</td>\n",
       "      <td>0</td>\n",
       "      <td>CA</td>\n",
       "      <td>1870-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASN00014016</td>\n",
       "      <td>18700101</td>\n",
       "      <td>PRCP</td>\n",
       "      <td>51</td>\n",
       "      <td>AS</td>\n",
       "      <td>1870-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1870</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         station  datetime obs_type  obs_value area datetime_dt  month  year\n",
       "27   ASN00075080  18700101     PRCP          0   AS  1870-01-01      1  1870\n",
       "144  SWE00138488  18700101     PRCP          2   SW  1870-01-01      1  1870\n",
       "139  SWE00100026  18700101     PRCP          0   SW  1870-01-01      1  1870\n",
       "70   CA006148100  18700101     TMIN        -44   CA  1870-01-01      1  1870\n",
       "69   CA006148100  18700101     TMAX          6   CA  1870-01-01      1  1870\n",
       "91   CA008205698  18700101     TMAX         17   CA  1870-01-01      1  1870\n",
       "129  NLE00101991  18700101     PRCP          0   NL  1870-01-01      1  1870\n",
       "120  ITE00100552  18700101     PRCP         47   IT  1870-01-01      1  1870\n",
       "93   CA008205698  18700101     PRCP          0   CA  1870-01-01      1  1870\n",
       "1    ASN00014016  18700101     PRCP         51   AS  1870-01-01      1  1870"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_weather_period = process_weather(1870)\n",
    "df_weather_period.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a7189d84de812b64c7424088e3ca325b",
     "grade": true,
     "grade_id": "problem_234_tests",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "78e78d64830c5518e7ef3173d94bf33c",
     "grade": false,
     "grade_id": "cell-7a8591d457df256a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "> **Ex. 2.X.3 (Not seen in module 2):** Try to plot the observations value of `df_weather_period` by running `df_weather_period.obs_value.plot()`. Something seems off, right? Now try to inspect the problematic subset of the dataframe by running `df_weather_period[df_weather_period.obs_value < -50]`. What can these three observations be characterized as? Drop _all_ observations from the associated station from `df_weather_period`, reset the index and drop the column with the old index. Store the dataframe back into the variable `df_weather_period`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a2de59076e97751d5e76fa532723f768",
     "grade": false,
     "grade_id": "problem_notseenexercises",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>datetime</th>\n",
       "      <th>obs_type</th>\n",
       "      <th>obs_value</th>\n",
       "      <th>area</th>\n",
       "      <th>datetime_dt</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>846746</th>\n",
       "      <td>CA008101170</td>\n",
       "      <td>18751231</td>\n",
       "      <td>TMIN</td>\n",
       "      <td>-61</td>\n",
       "      <td>CA</td>\n",
       "      <td>1875-12-31</td>\n",
       "      <td>12</td>\n",
       "      <td>1875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846943</th>\n",
       "      <td>USC00298072</td>\n",
       "      <td>18751231</td>\n",
       "      <td>TMIN</td>\n",
       "      <td>-128</td>\n",
       "      <td>US</td>\n",
       "      <td>1875-12-31</td>\n",
       "      <td>12</td>\n",
       "      <td>1875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846720</th>\n",
       "      <td>CA007021952</td>\n",
       "      <td>18751231</td>\n",
       "      <td>TMIN</td>\n",
       "      <td>-83</td>\n",
       "      <td>CA</td>\n",
       "      <td>1875-12-31</td>\n",
       "      <td>12</td>\n",
       "      <td>1875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846738</th>\n",
       "      <td>CA008100500</td>\n",
       "      <td>18751231</td>\n",
       "      <td>TMIN</td>\n",
       "      <td>-122</td>\n",
       "      <td>CA</td>\n",
       "      <td>1875-12-31</td>\n",
       "      <td>12</td>\n",
       "      <td>1875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846594</th>\n",
       "      <td>AU000005901</td>\n",
       "      <td>18751231</td>\n",
       "      <td>TMAX</td>\n",
       "      <td>-80</td>\n",
       "      <td>AU</td>\n",
       "      <td>1875-12-31</td>\n",
       "      <td>12</td>\n",
       "      <td>1875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>USC00271682</td>\n",
       "      <td>18700101</td>\n",
       "      <td>TMIN</td>\n",
       "      <td>-56</td>\n",
       "      <td>US</td>\n",
       "      <td>1870-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>EZE00100082</td>\n",
       "      <td>18700101</td>\n",
       "      <td>TMIN</td>\n",
       "      <td>-52</td>\n",
       "      <td>EZ</td>\n",
       "      <td>1870-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>USC00043157</td>\n",
       "      <td>18700101</td>\n",
       "      <td>TMIN</td>\n",
       "      <td>-133</td>\n",
       "      <td>US</td>\n",
       "      <td>1870-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>GME00125218</td>\n",
       "      <td>18700101</td>\n",
       "      <td>TMIN</td>\n",
       "      <td>-55</td>\n",
       "      <td>GM</td>\n",
       "      <td>1870-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>CA006166416</td>\n",
       "      <td>18700101</td>\n",
       "      <td>TMIN</td>\n",
       "      <td>-78</td>\n",
       "      <td>CA</td>\n",
       "      <td>1870-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1870</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31194 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            station  datetime obs_type  obs_value area datetime_dt  month  \\\n",
       "846746  CA008101170  18751231     TMIN        -61   CA  1875-12-31     12   \n",
       "846943  USC00298072  18751231     TMIN       -128   US  1875-12-31     12   \n",
       "846720  CA007021952  18751231     TMIN        -83   CA  1875-12-31     12   \n",
       "846738  CA008100500  18751231     TMIN       -122   CA  1875-12-31     12   \n",
       "846594  AU000005901  18751231     TMAX        -80   AU  1875-12-31     12   \n",
       "...             ...       ...      ...        ...  ...         ...    ...   \n",
       "169     USC00271682  18700101     TMIN        -56   US  1870-01-01      1   \n",
       "107     EZE00100082  18700101     TMIN        -52   EZ  1870-01-01      1   \n",
       "159     USC00043157  18700101     TMIN       -133   US  1870-01-01      1   \n",
       "112     GME00125218  18700101     TMIN        -55   GM  1870-01-01      1   \n",
       "86      CA006166416  18700101     TMIN        -78   CA  1870-01-01      1   \n",
       "\n",
       "        year  \n",
       "846746  1875  \n",
       "846943  1875  \n",
       "846720  1875  \n",
       "846738  1875  \n",
       "846594  1875  \n",
       "...      ...  \n",
       "169     1870  \n",
       "107     1870  \n",
       "159     1870  \n",
       "112     1870  \n",
       "86      1870  \n",
       "\n",
       "[31194 rows x 8 columns]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_weather_period.obs_value.plot()\n",
    "plt.show()\n",
    "df_weather_period[df_weather_period.obs_value < -50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5971a3b2c04c14fb5fb5f180e25ff481",
     "grade": true,
     "grade_id": "problem_notseenexercises_tests",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b1b79752e5634da4d89aa3ae634563e0",
     "grade": false,
     "grade_id": "cell-c2f8ff075ab551a8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "> **Ex. 2.3.2:** \n",
    "Continuing with the `df_weather_period` from last exercise, do the following:\n",
    "> 1. Convert the `area` column to a categorical variable. \n",
    "> 2. Transform the `obs_value` column from a continuous to a categorical variable by partitioning it into `3` intervals. The first interval should contain observations with values of `obs_value` up to the 10% quantile. The second interval should contain observations with values of `obs_value` up to the 90% quantile. The third interval should contain the rest of the observations. Call this new column for `obs_value_cat`.  This can be done using the `pd.qcut()` method.\n",
    "> 3. Make another column with  `obs_value` as a categorical variable but this time label the 3 intervals as `[\"cold\", \"medium\", \"hot\"]`. This can be done by specifying the `labels` parameter in the `pd.qcut()` method of pandas. Call this new column for `obs_value_cat_labeled`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5a0243b6c65b39af72e8d1efead106e8",
     "grade": false,
     "grade_id": "problem_232",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'Series'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19600/2508603656.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_weather_period\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"area\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"category\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5485\u001b[0m         ):\n\u001b[0;32m   5486\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5487\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5488\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5489\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'Series'"
     ]
    }
   ],
   "source": [
    "df_weather_period.Series(\"area\", dtype=\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "station                object\n",
       "datetime                int64\n",
       "obs_type               object\n",
       "obs_value               int64\n",
       "area                   object\n",
       "datetime_dt    datetime64[ns]\n",
       "month                   int64\n",
       "year                    int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_weather_period.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6ea686468a1612c1453d6013671443b9",
     "grade": true,
     "grade_id": "problem_232_tests",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d0e767d450ff726563ebe1bdb729215f",
     "grade": false,
     "grade_id": "cell-77eabac0ab0cbce5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Problems from Exercise Set 3:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1f6944ea47bde40b92ba269f19d16439",
     "grade": false,
     "grade_id": "cell-4975a2e1ab215936",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "> **Ex. 3.3.1:** Compute the mean and median maximum daily temperature for each month-year-station pair on the dataframe `df_weather_period` from last exercise by using the _split-apply-combine_ procedure. Store the results in new columns `tmax_mean` and `tmax_median`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ce92e895d0a63283094fe6c661cb5b66",
     "grade": false,
     "grade_id": "problem_331",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b200933c81339b97661155bc29d76cef",
     "grade": true,
     "grade_id": "problem_331_tests",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0e4d376c6fe462ddc61d2839b982968b",
     "grade": false,
     "grade_id": "cell-7e77713f98953bac",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "> **Ex. 3.3.2:** Plot the monthly max,min, mean, first and third quartiles for maximum temperature for the station with ID _'CA006110549'_ from `df_weather_period`.\n",
    "\n",
    "> *Hint*: the method `describe` computes all these measures. Try to make your plot look like the one below. \n",
    "\n",
    "<img src=\"station_data_plot.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ca1afdbf1edee8beacbfc1e95d6ac2e4",
     "grade": true,
     "grade_id": "problem_332_tests",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cf7d78380538170cdb3f8da6d976c6cd",
     "grade": false,
     "grade_id": "cell-539af69a1ea23069",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "> **Ex. 3.3.3: (MODIFIED FOR ASSIGNMENT 1)** We want to use the location data of the weather stations and merge this onto `df_weather_period`. The file with station location data is called  `ghcnd-stations.txt` and is stored in the `data.zip` file. Therefore, by Ex. 2.X.2, it should now be located in the `data` folder of this directory. `pandas` has a function named [`read_fwf`](https://pandas.pydata.org/docs/reference/api/pandas.read_fwf.html) which can be used to read a txt file with a fixed width format (each variable spans a fixed amount of columns). The function is neat and can infer how many columns each variable spans automatically (if the `infer_nrows` parameter is set properly). One can also manually set the `colspecs` parameter equal to a list of tuples containing the fixed-width intervals that the variables span. In the following exercise we will use some extra time and do the job manually to practice our txt file and string skills. Specifically, we will extract the list of tuples with fixed-widht information together with the column names and datatypes from the `ghcnd-stations-column-metadata.txt` file (also included in the `data.zip` file). \n",
    "\n",
    "> The `ghcnd-stations-column-metadata.txt` file looks like this: \n",
    "\n",
    "```\n",
    "------------------------------\n",
    "Variable   Columns   Type\n",
    "------------------------------\n",
    "ID            1-11   Character\n",
    "LATITUDE     13-20   Real\n",
    "LONGITUDE    22-30   Real\n",
    "ELEVATION    32-37   Real\n",
    "STATE        39-40   Character\n",
    "NAME         42-71   Character\n",
    "GSN FLAG     73-75   Character\n",
    "HCN/CRN FLAG 77-79   Character\n",
    "WMO ID       81-85   Character\n",
    "------------------------------\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f4d926a239ad69a32e6ddcb443ef42a0",
     "grade": false,
     "grade_id": "cell-6a3113e42875692a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "> **Ex. 3.3.3.1:** Read the `ghcnd-stations-column-metadata.txt` using the `with` keyword, see [here](https://docs.python.org/3/tutorial/inputoutput.html#reading-and-writing-files), and store it in a variable called `column_metadata`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "be143fcf053d269b2048157e33dc225c",
     "grade": false,
     "grade_id": "3331",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1406fd53b4dd29083588279108f8b861",
     "grade": true,
     "grade_id": "3331-test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5d348ada2f5d006ebbb11b024f7139bc",
     "grade": false,
     "grade_id": "cell-9c66cca32bfbef31",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "> **Ex. 3.3.3.2:** Split `column_metadata` into a list of strings by applying the method `split` with the proper argument. Subset the resulting list and extract all lines from index `3` to `12` (non-inclusive) of the variable. Store the final list in a variable named `lines`. Inspect the result to make sure the relevant rows of the txt file has been extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6850caaabe8ccf9c93f8449beda38043",
     "grade": false,
     "grade_id": "3332",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a01223ced1b81abc7bb54537a1923fd3",
     "grade": true,
     "grade_id": "3332-tests",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7a2d97eb10f8245bcb67a28a98be2d91",
     "grade": false,
     "grade_id": "cell-6d6084e723953822",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "> **Ex. 3.3.3.3:** Inspecting each line of the `lines` variable we see that the information about the column widths are all located from index `13` up and including index `17`. Finish the `get_colspecs` function below to extract the fixed width information from the `lines` variable by completing the steps below:\n",
    "1. Use a list comprehension to loop through each line of the file\n",
    "2. Index each line by the relevant indices written above\n",
    "3. Strip leading whitespace of each element (if necessary)\n",
    "\n",
    "> Finally, apply `get_colspecs` to the `lines` variable and store the result in a new variable called `colspecs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ca2823ed345d0dd66e8782cd4da05ea2",
     "grade": false,
     "grade_id": "3333",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def get_colspecs(lines):\n",
    "    \"\"\"Extracts colspecs from `ghcnd-stations-column-metadata.txt`.\n",
    "    \n",
    "    Args:\n",
    "        lines (list[str]): \n",
    "            list of relevant rows from `ghcnd-stations-column-metadata.txt` \n",
    "    \n",
    "    Returns:\n",
    "        (list[str]): \n",
    "            list of extracted colspecs i.e. ['1-11', '13-20', ..., '81-85']\n",
    "    \"\"\"\n",
    "    colspec_idx_start = 13\n",
    "    colspec_idx_end = 17 + 1  # Including idx 17\n",
    "    # Insert missing line\n",
    "    return colspecs\n",
    "\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "44cd16c209eaf640a81923fb6c6ad3f1",
     "grade": true,
     "grade_id": "3333-tests",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b4c3b22be2785fd9a8e77273cb088905",
     "grade": false,
     "grade_id": "cell-6d9084804240b2d8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "> **Ex. 3.3.3.4:** Write a function named `get_colspec_pair` which takes as input a string variable named `colspec` and returns a tuple of integers. Specifically, the function should take a string similar to each element of `colspecs`, split this string by `-` and return a tuple of integers where\n",
    "1. The first integer should have `1` subtracted from it (Python is 0-indexed!)\n",
    "2. The second integer should stay as it is (the intervals provided to the pandas function `read_fwf` should be non-inclusive)\n",
    "> As an example, applying the function to `\"1-11\"` and `\"13-20\"` should yield the following results:\n",
    "\n",
    "```python\n",
    "print(get_colspec_pair(\"1-11\"))\n",
    "## output: (0, 11)\n",
    "\n",
    "print(get_colspec_pair(\"13-20\"))\n",
    "## output: (12, 20)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7fa3780ae35b45977761ba2fb454216a",
     "grade": false,
     "grade_id": "3334",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8fee8d5b0d56d0ec1a96ed593c59a0d4",
     "grade": true,
     "grade_id": "3334-tests",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0ff7f17567aa4e2fbb44af24bdbcc986",
     "grade": false,
     "grade_id": "cell-cbaa1e1dca8e3015",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "> **Ex. 3.3.3.5:** Use the `get_colspec_pair` function in a list comprehension where you apply the function to each element in `colspecs`. Store the result in a variable named `colspec_pairs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3afbf83d84156e24b17573026dfa8248",
     "grade": false,
     "grade_id": "3335",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a12fae1b1b368de38f3c30a3e1cdc965",
     "grade": true,
     "grade_id": "3335-tests",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2be26e96b4592760cfc20c18c6da9b1e",
     "grade": false,
     "grade_id": "cell-5535ad3d8666836b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "> **Ex. 3.3.3.6:** Because the fixed width column information spans the interval from `13` up and including index `17`, we know that the entries from `0` to `13` (non-inclusive) are the column names and the entries from `18` to the end of each line are the data types. Write two functions named `get_column_names` and `get_column_dtypes` which return a list of column names and a list of the data types of the columns, respectively. Remember to strip all redundant whitespace using the string method `strip`. Apply the function `get_column_names` to the `lines` variable and store the output in a variable named `column_names`. Likewise, apply the function `get_column_dtypes` to the `lines` variable and store the output in a variable named `column_dtypes`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f19450632f6c6d1d4d948405258b3f5c",
     "grade": false,
     "grade_id": "3336",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8a4ad3c2aaa3e244b71d02a9c0d99303",
     "grade": true,
     "grade_id": "3336-tests",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "42c0ef12aadd154859e3b41b8c7fabc1",
     "grade": false,
     "grade_id": "cell-6a9d81f37628d1ad",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "> **Ex. 3.3.3.7:** Replace each `\"character\"` entry with `\"str\"` and each `\"real\"` entry with `\"float32\"` of the list `column_dtypes`. Store the result of this in the same variable `column_dtypes`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2c43672a0ccde0a6cb5b628a91dfcd4d",
     "grade": false,
     "grade_id": "3337",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f3afd09a2073e36c109317f6e1f1b56e",
     "grade": true,
     "grade_id": "3337-tests",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "517454579c02edf82638e4d2f6769d05",
     "grade": false,
     "grade_id": "cell-75834af9070629b1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "> **Ex. 3.3.3.8:** Load the `ghcnd-stations.txt` data using the `read_fwf` method of pandas setting the `names` parameter equal to `column_names` and the `colspecs` parameter equal to  `colspec_pairs`. Store the result in a variable named `locations`. Next, use the `astype` method on `locations` to set the dtypes of the columns. Use the `col_to_dtype` mapping below as input argument to `astype`. Finally, rename the `id` column to `station` and left-merge `locations` onto `df_weather_period`. Store the merged dataframe in the variable `df_weather_merged`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f95d9887f5f7d1bb9294ef49c9ac05e3",
     "grade": true,
     "grade_id": "3338",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "col_to_dtype = dict(zip(column_names, column_dtypes))\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b9a4a76770858c976a5b06ed3ae844c1",
     "grade": false,
     "grade_id": "cell-5ba4eb25c926ef77",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "> **Ex. 3.3.3.9:** Subset `df_weather_period` by all weather stations in Ontario (all stations in Ontario have `state == \"ON\"`) and store the resulting DataFrame in `df_ontario`. Compute the average `obs_value` for each `station`. Store the result in a dictionary named `avg_obs_value_ontario` with the keys being the station names and the values the average `obs_value`. Finally, subset the `locations` dataframe by the querying all stations contained in the keys of `avg_obs_value_ontario`. Store the result in `locations_ontario`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "281bdf9651d8963912d805659386a298",
     "grade": false,
     "grade_id": "3339",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b0c4d941c8aa454f62466c826d87602a",
     "grade": true,
     "grade_id": "3339-test",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4c3a1d9147bc363623dcefcb7c27d5d5",
     "grade": false,
     "grade_id": "cell-8d4c53302d51c9db",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "> **Ex. 3.3.3.10 (OPTIONAL)**: The following exercise does not count towards the grade of this assignment. Let's try to plot the stations for Ontario on a map of Ontario. We'll use the [`folium`](http://python-visualization.github.io/folium/) package to do this. This package is not pre-installed with `anaconda`. Run the cell below to install the package or open up your terminal, activate your preferred conda environment and type `!pip install folium`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install folium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8765bee40dfff161e74121cdcf5fcb42",
     "grade": false,
     "grade_id": "cell-444d95c01e37753f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "> **Ex. 3.3.3.10 (continued)**:\n",
    "> We want to plot the stations in `locations_ontario` on top of a map of Ontario. To do this, we need to create a `folium.Marker` for each station and place this on the folium map named `m` in the cell below starting with `import folium`. To accomplish this do the following:\n",
    "- Iterate through the `zipper` defined in the cell below using a list comprehension and apply the `get_marker` function at each iteration. \n",
    "    - The `zipper` object yields a tuple of 4 values in each iteration. \n",
    "- The `avg_temp` argument of `get_marker` should take the value of each given station from the `avg_obs_value_ontario` dictionary created in the previous exercise. If the loop variable corresponding to `locations_ontario.station` is named `station_id` the value can be computed by subsetting the dictionary as  `avg_obs_value_ontario[station_id]`.\n",
    "- Store the result in a variable named `markers_ontario`. The result should be a list of `folium.Markers` for each of the stations.\n",
    "\n",
    "The resulting plot should be an interactive plot similar to the one in the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b4cd34d87209cc1d736bf17963ca1278",
     "grade": false,
     "grade_id": "cell-09786db74bccea07",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Resulting folium plot\n",
    "from IPython.display import Image\n",
    "Image(filename='ontario-example-plot.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4402f4bff9fb1f9e77ba879131dfdef4",
     "grade": true,
     "grade_id": "33310",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import folium\n",
    "\n",
    "\n",
    "def get_marker(lat, lon, station_name, avg_obs_value, icon='cloud', color=\"blue\"):\n",
    "    \"\"\"Creates a `folumn.Marker` for a given station\n",
    "    \n",
    "    Args:\n",
    "        (lat): lattitude of station\n",
    "        (lon): longitude of station\n",
    "        (station_name): name of station\n",
    "        (avg_obs_value): avg. obs_value for given station\n",
    "        \n",
    "    Returns:\n",
    "        (folium.Marker): object to be added to a folium map\n",
    "    \"\"\"\n",
    "    popup = \"\\n\".join([station_name, f\"Avg. obs_value: {avg_obs_value:.2f}\"])\n",
    "    marker = folium.Marker(\n",
    "        location=[lat, lon],\n",
    "        popup=popup,\n",
    "        icon=folium.Icon(icon=icon, color=color, )\n",
    "    )\n",
    "    return marker\n",
    "\n",
    "\n",
    "# Create folium map centered on Ontario\n",
    "# COORDS_ONTARIO = (51.730703, -86.938937)\n",
    "COORDS_ONTARIO = (43.40168574192175, -80.33021323830818)\n",
    "m = folium.Map(location=COORDS_ONTARIO, zoom_start=6)\n",
    "\n",
    "# Zipper object to iterate through\n",
    "zipper = zip(\n",
    "    locations_ontario.latitude,\n",
    "    locations_ontario.longitude,\n",
    "    locations_ontario.name,\n",
    "    locations_ontario.station   \n",
    ")\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "# add weather station markers to map \n",
    "for station_marker in markers_ontario:  \n",
    "    station_marker.add_to(m)\n",
    "m  # Display map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "eaf086f4f6724e090ef66a74eff4517e",
     "grade": false,
     "grade_id": "cell-422d30deb292b4c7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Problems from Exercise Set 4:\n",
    "\n",
    "> **Ex. 4.3.5 (sligthly modified):** This exercise consists of a set of small subelements: \n",
    ">\n",
    "> 0. Show the first five rows of the titanic dataset. What information is in the dataset?\n",
    "> 1. Use a barplot to show the probability of survival for men and women within each passenger class. \n",
    "> 2. Can you make a boxplot showing the same information (why/why not?). \n",
    "> 3. Show a boxplot for the fare-prices within each passenger class. \n",
    "> 4. Create a new subfolder as done in Ex. 2.X.1 this time named `figs`. Use the same approach as in Ex. 2.X.1 and store the `Path` object in a variable named `fp_figs`. \n",
    "> 5. Combine the two of the figures you created above into a two-panel figure and save it on your computer in the `figs` subfolder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e46d24e4bd08f8870982dd932ddd15f1",
     "grade": true,
     "grade_id": "problem_435",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 4.3.6:** Using the iris flower dataset, draw a scatterplot of sepal length and petal length. Include a second order polynomial fitted to the data. Add a title to the plot and rename the axis labels.\n",
    ">\n",
    "> _Write 3 sentences:_ Is this a meaningful way to display the data? What could we do differently?\n",
    ">\n",
    "> For a better understanding of the dataset this image might be useful:\n",
    "\n",
    "> <img src=\"example-iris-q436.png\" alt=\"Drawing\" style=\"width: 200px;\"/>\n",
    ">\n",
    "> _Hint:_ Use the `.regplot` method from seaborn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7e41badd527517260b61cead987a91cf",
     "grade": true,
     "grade_id": "problem_436",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4330f62f04b07d60e818eb1893bbf82d",
     "grade": false,
     "grade_id": "cell-e6d0c56f1cf535c5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "> **Ex. 4.3.7:** Use [pairplot with hue](https://seaborn.pydata.org/generated/seaborn.pairplot.html) to create a figure that clearly shows how the different species vary across measurements in the iris dataset. Change the color palette and remove the shading from the density plots. _Bonus:_ Try to explain how the `diag_kws` argument works (_hint:_ [read here](https://stackoverflow.com/questions/1769403/understanding-kwargs-in-python))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "19e3feab810ee078ec29408d99334983",
     "grade": true,
     "grade_id": "problem_437",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
